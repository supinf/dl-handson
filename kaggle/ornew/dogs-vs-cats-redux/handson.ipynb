{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KerasによるAlexNetを用いた犬猫分類モデル\n",
    "\n",
    "Author: 古川新 ([facebook](https://www.facebook.com/old.r.new), [web](http://ornew.net/))\n",
    "\n",
    "TensorFlowをバックエンドに、Kerasを用いて犬猫分類モデルを構築します。モデル構成はAlexNet（[論文](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)）を用います。\n",
    "\n",
    "犬猫のデータセットは[Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)を用います。訓練用データセット(`./train/*.jpg`)とテスト用データセット(`./test/*.jpg`)を事前に用意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(722)\n",
    "\n",
    "from keras.initializers import TruncatedNormal, Constant\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを準備します。ここでは、画像をすべて224x224のサイズにリサイズしています。\n",
    "\n",
    "AlexNetでは本来、256x256の画像データからランダムに224x224に切り抜いた画像を入力として扱っています。オーバーフィットを抑える効果がありますが、データが増えることにより訓練に時間がかかるため、今回は224x224のまま入力として扱います。\n",
    "\n",
    "訓練データは25000枚、テストデータは12500枚です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "TRAIN_DIR = 'train/'\n",
    "TEST_DIR = 'test/'\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "FORCE_CONVERT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read(name):\n",
    "    return cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "\n",
    "def convert(img):\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def save(name, img):\n",
    "    cv2.imwrite(CACHE_DIR + name, img)\n",
    "    return img\n",
    "\n",
    "def ls(dirname):\n",
    "    return [dirname + i for i in os.listdir(dirname)]\n",
    "\n",
    "# 毎回変換していると時間がかかるので、一度変換したらキャッシュします\n",
    "# キャッシュ用のディレクトリを作ります\n",
    "if not os.path.exists(CACHE_DIR):\n",
    "    os.mkdir(CACHE_DIR)\n",
    "if not os.path.exists(CACHE_DIR + TRAIN_DIR):\n",
    "    os.mkdir(CACHE_DIR + TRAIN_DIR)\n",
    "if not os.path.exists(CACHE_DIR + TEST_DIR):\n",
    "    os.mkdir(CACHE_DIR + TEST_DIR)\n",
    "\n",
    "sys.stdout.write('Loading... ')\n",
    "\n",
    "train_files = ls(CACHE_DIR + TRAIN_DIR)\n",
    "train = np.array([read(i) for i in train_files])\n",
    "\n",
    "test_files = ls(CACHE_DIR + TEST_DIR)\n",
    "test = np.array([read(i) for i in test_files])\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "if FORCE_CONVERT or len(train) < 25000:\n",
    "    sys.stdout.write('Process train data... ')\n",
    "    train =  np.array([save(TRAIN_DIR + i, convert(read(TRAIN_DIR + i))) for i in os.listdir(TRAIN_DIR)])\n",
    "    train_files = ls(CACHE_DIR + TRAIN_DIR)\n",
    "    print('Done!')\n",
    "    \n",
    "if FORCE_CONVERT or len(test) < 12500:\n",
    "    sys.stdout.write('Process test data... ')\n",
    "    test =  np.array([save(TEST_DIR + i, convert(read(TEST_DIR + i))) for i in os.listdir(TEST_DIR)])\n",
    "    test_files = ls(CACHE_DIR + TEST_DIR)\n",
    "    print('Done!')\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "print(\"Test shape: {}\".format(test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ラベルデータを用意します。このデータセットではファイル名の先頭の文字列がそのままラベルになっているので、犬を0、猫を1としてラベルの配列を作ります。その後、to_categorical関数によりOHVに変換しています。\n",
    "\n",
    "また、データが均等であることを確認するために、データの枚数をグラフで表示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in train_files:\n",
    "    if 'dog' in i:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "sns.countplot(labels)\n",
    "plt.title('Dogs and Cats')\n",
    "\n",
    "labels = to_categorical(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの一部を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dogs = [i for i in train_files if 'dog' in i]\n",
    "train_cats = [i for i in train_files if 'cat' in i]\n",
    "\n",
    "def show_train_image(i):\n",
    "    dog = read(train_dogs[i])\n",
    "    cat = read(train_cats[i])\n",
    "    pair = np.concatenate((dog,cat), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(0,5):\n",
    "    show_train_image(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNetを構築します。元の論文ではBatchNormalizationではなくLocal Response Normalizationというものが用いられていますが、Kerasからは何故か実装が削除されてしまったのでBatchNormalizationになっています（たぶん問題ない）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def conv2d(filters, kernel_size, strides=1, bias_init=1, **kwargs):\n",
    "    trunc = TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "    cnst = Constant(value=bias_init)\n",
    "    return Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=trunc,\n",
    "        bias_initializer=cnst,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def dense(units, **kwargs):\n",
    "    trunc = TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "    cnst = Constant(value=1)\n",
    "    return Dense(\n",
    "        units,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=trunc,\n",
    "        bias_initializer=cnst,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def AlexNet():\n",
    "    model = Sequential()\n",
    "\n",
    "    # 第1畳み込み層\n",
    "    model.add(conv2d(96, 11, strides=(4,4), bias_init=0, input_shape=(ROWS, COLS, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 第２畳み込み層\n",
    "    model.add(conv2d(256, 5, bias_init=1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 第３~5畳み込み層\n",
    "    model.add(conv2d(384, 3, bias_init=0))\n",
    "    model.add(conv2d(384, 3, bias_init=1))\n",
    "    model.add(conv2d(256, 3, bias_init=1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    " \n",
    "    # 密結合層\n",
    "    model.add(Flatten())\n",
    "    model.add(dense(4096))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(dense(4096))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 読み出し層\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=SGD(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを構築し、summary関数で構造を表示します。\n",
    "\n",
    "訓練データのうち25%をバリデーションデータとして扱います。最大15エポック、かつvalidation lossを監視して改善が見受けられない場合は早急に訓練を打ち切ります。\n",
    "メモリが足りない場合はバッチサイズを減らしてください。\n",
    "\n",
    "データをシャッフルするため、実行のたびに訓練結果は変わります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = AlexNet()\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "history = model.fit(train, labels, epochs=15, batch_size=128, shuffle=True, validation_split=0.25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練履歴をグラフで示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['acc'],\"o-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_acc'],\"o-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストを行い、結果の一部を画像とともに表示します。\n",
    "\n",
    "結構間違えます。明確な指針が有るわけではないですが、私個人の見解としては、実用的な正答率は98%が最低ラインだと思います。\n",
    "\n",
    "もし90%だとしたら、「10回に１回間違えた」と考えれば、それがどれだけ悪い結果なのか容易に想像がつくと思います。98%でも、「５０回に１回は間違えた」わけです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    print('Dog : {}'.format(predictions[i][0]))\n",
    "    print('Cat : {}'.format(predictions[i][1]))\n",
    "    if predictions[i][0] > predictions[i][1]:\n",
    "        print('I am {:.2%} sure this is a Dog.'.format(predictions[i][0]))\n",
    "    else:\n",
    "        print('I am {:.2%} sure this is a Cat.'.format(predictions[i][1]))\n",
    "        \n",
    "    plt.imshow(test[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement\n",
    "\n",
    "冒頭でも述べたように、今回はオーバーフィットを減らすためのデータ増強を行っていません。\n",
    "\n",
    "AlexNetは、ランダムな切り抜き、平行移動、水平反射、RGB強度の変更などを行い、精度が改善したことを論文で示しています。\n",
    "\n",
    "実際にこういったデータ増強は大きな効果を示すことが知られています。論文中でも、データの増強を行わない場合はオーバーフィットに悩まされる結果になったと述べられています。\n",
    "\n",
    "ランダムな切り抜き、平行移動、水平反射などは画像認識では今や一般的で、十分に効果が期待できます。また、RGB強度の変更は自然画像に対して特に有効であると言われています。手法はこれらだけではなく、画像にノイズを加えたり、回転を行う方法などもあります。\n",
    "\n",
    "実際にデータを増強し、精度が改善することをぜひ確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"Imagenet classification with deep convolutional neural networks.\" Advances in neural information processing systems. 2012. [[pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)]\n",
    "- Srivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting.\" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [[pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)]\n",
    "\n",
    "- TensorFlow [https://www.tensorflow.org/](https://www.tensorflow.org/)\n",
    "- Keras (ja) [https://keras.io/ja/](https://keras.io/ja/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_このノートブックは[MaruLabo × JAWS-UG AI #3](https://jawsug-ai.connpass.com/event/59674/)でハンズオンの課題として使うために作成されました。_\n",
    "\n",
    "Arata Furukawa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
